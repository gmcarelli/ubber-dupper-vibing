{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of the Modular LLM File Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llm_host.ollama_client import OllamaClient\n",
    "from llm_host.model_manager import ModelManager\n",
    "from llm_host.chat_session import ChatSession\n",
    "from improved_goggles.processor import process_files\n",
    "\n",
    "# --- Configuration ---\n",
    "OLLAMA_HOST = \"http://localhost:11434\"\n",
    "MODEL_NAME = \"llama3\"\n",
    "DATA_FOLDER = \"example_data_folder\"\n",
    "GUIDELINES_FILE = \"fleubers.txt\"\n",
    "\n",
    "# --- Setup Sample Data ---\n",
    "data_path = Path(DATA_FOLDER)\n",
    "data_path.mkdir(exist_ok=True)\n",
    "\n",
    "guidelines_content = \"You are an assistant that summarizes text into a single, concise sentence.\"\n",
    "(data_path / GUIDELINES_FILE).write_text(guidelines_content, encoding=\"utf-8\")\n",
    "\n",
    "(data_path / \"file1.txt\").write_text(\"Artificial intelligence is rapidly transforming the world.\", encoding=\"utf-8\")\n",
    "(data_path / \"file2.txt\").write_text(\"Natural language processing is a fascinating subfield of AI.\", encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Data folder '{DATA_FOLDER}' and sample files created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Execute the Processor ---\n",
    "try:\n",
    "    # 1. Initialize and connect the client\n",
    "    ollama_client = OllamaClient()\n",
    "    ollama_client.connect(OLLAMA_HOST)\n",
    "    print(f\"Connected to Ollama host at {OLLAMA_HOST}\")\n",
    "    \n",
    "    # 2. (Optional) Use ModelManager to interact with models\n",
    "    model_manager = ModelManager(ollama_client)\n",
    "    print(\"Available Models:\")\n",
    "    print(model_manager.list_models())\n",
    "    \n",
    "    # 3. Create a chat session\n",
    "    chat_session = ChatSession(ollama_client, MODEL_NAME)\n",
    "    print(f\"Chat session created with model '{MODEL_NAME}'.\")\n",
    "    \n",
    "    # 4. Process the files\n",
    "    print(f\"Processing files in '{DATA_FOLDER}'...\")\n",
    "    process_files(DATA_FOLDER, chat_session, guidelines_file=GUIDELINES_FILE)\n",
    "    print(\"Processing complete.\")\n",
    "    \n",
    "    # --- Verify Results ---\n",
    "    results_file = Path(\"results\") / f\"{DATA_FOLDER}.txt\"\n",
    "    if results_file.is_file():\n",
    "        print(f\"\\nResults file content '{results_file}':\")\n",
    "        print(results_file.read_text(encoding=\"utf-8\"))\n",
    "    else:\n",
    "        print(f\"\\nResults file '{results_file}' not found.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
